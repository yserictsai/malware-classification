# Feature selection by XGBOOST

def create_feature_map(features):
    outfile = open('xgb.fmap', 'w')
    i = 0
    for feat in features:
        outfile.write('{0}\t{1}\tq\n'.format(i, feat))
        i = i + 1
    outfile.close()
# data_col = v8_training_data.drop(['FileID','Label'],1)        
# create_feature_map(data_col.columns)

import xgboost as xgb
def xgboost_fs(X_train, y_train, ITER, Filename, **xgb_params):
    xgb_params = **xgb_params
    num_rounds = ITER
    dtrain = xgb.DMatrix(X_train, label=y_train)
    gbdt = xgb.train(xgb_params, dtrain, num_rounds)
    fscore = gbdt.get_fscore(str(Filename))
    features = sorted(fscore, key=fscore.get, reverse=True)
    return features
# v8_select = v8_data[features]



def corr_fs(df):
    # Create correlation matrix
    corr_matrix = df.corr().abs()
    # Select upper triangle of correlation matrix
    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))
    # Find index of feature columns with correlation greater than 0.95
    to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]
    select_df = df.drop(df[to_drop], axis=1)
    return select_df





def randomforest_fs(X_train, X_test, y_train):
    clf_se = RF(n_estimators=500, n_jobs=-1,random_state = 0)
    clf_se.fit(X_train, y_train)
    X_train = np.array(clf_se.transform(X_train, '1.25*mean'))
    X_test = np.array(clf_se.transform(X_test, '1.25*mean'))
    return X_train, X_test





