# Start From X_train, y_train, X_test.
import gc
import pickle
import numpy as np
import pandas as pd
from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import Imputer
from sklearn.cross_validation import StratifiedKFold
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier



# Basic Model

def basic_model(y):
    if y == 'rf':
        clf = RandomForestClassifier(n_jobs=3,n_estimators=67,max_depth=12,min_samples_leaf=3)
    elif y == 'et':
        clf = ExtraTreesClassifier(n_jobs=3,max_depth=9,min_samples_leaf=5,n_estimators=46)
    elif y == 'ada':
        clf = AdaBoostClassifier()
    elif y == 'gb':
        clf = GradientBoostingClassifier()
    elif y == 'lg':
        clf = LGBMClassifier(n_jobs=3)

    return clf

rf = basic_model('rf')
param_rf = { 
    'n_estimators': sp_randint(10, 300),
    'max_depth': sp_randint(2, 18),
    'min_samples_leaf': sp_randint(2, 18)
}
rf_fit = random_search(rf, X_train, y_train, niter=20, **param_rf)
rf_best_score = rf_fit.best_score_
rf_best_params = rf_fit.best_params_
pickle.dump(rf_best_params, open('rf_param_info.p', 'wb'))
print('Best rf params: ', rf_best_params)
print('Best rf Score: ', rf_best_score)


et = basic_model('et')
param_et = { 
    'n_estimators': sp_randint(10, 100),
    'max_depth': sp_randint(2, 18),
    'min_samples_leaf': sp_randint(2, 18)
}
et_fit = random_search(et, X_train, y_train, niter=20, **param_et)
et_best_score = et_fit.best_score_
et_best_params = et_fit.best_params_
pickle.dump(et_best_params, open('et_param_info.p', 'wb'))
print('Best et params: ', et_best_params)
print('Best et Score: ', et_best_score)



ada = basic_model('ada')
param_ada = {
    'n_estimators': sp_randint(10, 500),
    'learning_rate': sp_uni(0.003, 0.5)
}
ada_fit = random_search(ada, X_train, y_train, niter=20, **param_ada)
ada_best_score = ada_fit.best_score_
ada_best_params = ada_fit.best_params_
pickle.dump(ada_best_params, open('ada_param_info.p', 'wb'))
print('Best ada params: ', ada_best_params)
print('Best ada Score: ', ada_best_score)



gb = basic_model('gb')
param_gb = {
    'n_estimators': sp_randint(100, 500),
    'learning_rate': sp_uni(0.003, 0.5),
    'max_depth': sp_randint(2, 18),
    'min_samples_split': sp_randint(2, 28),
    'subsample': sp_uni(loc=0, scale=1)
}
gb_fit = random_search(gb, X_train, y_train, niter=20, **param_gb)
gb_best_score = gb_fit.best_score_
gb_best_params = gb_fit.best_params_
pickle.dump(gb_best_params, open('gb_param_info.p', 'wb'))
print('Best gb params: ', gb_best_params)
print('Best gb Score: ', gb_best_score)



lg = basic_model('lg')
param_lg = {"max_depth": sp_randint(25, 80),
            "learning_rate" : sp_uni(0.003, 0.5),
            "num_leaves": sp_randint(250, 800),
            "n_estimators": sp_randint(100, 500),
            "subsample" : sp_uni(loc=0, scale=1),
            "reg_lambda" : sp_uni(0.6, 2),
             }
lg_fit = random_search(lg, X_train, y_train, niter=20, **param_lg)
lg_best_score = lg_fit.best_score_
lg_best_params = lg_fit.best_params_
pickle.dump(lg_best_params, open('lg_param_info.p', 'wb'))
print('Best lg params: ', lg_best_params)
print('Best lg Score: ', lg_best_score)


# Stacking Model
ntrain = X_train.shape[0]
ntest = X_test.shape[0]
SEED = 9527 # for reproducibility
NFOLDS = 3 # set folds for out-of-fold prediction
skf = StratifiedKFold(y_train, n_folds=NFOLDS)


def get_oof(clf, X_train, y_train, X_test):
    oof_train = np.zeros((ntrain,))
    oof_test = np.zeros((ntest,))
    oof_test_skf = np.empty((NFOLDS, ntest))

    for i, (train_index, test_index) in enumerate(skf):
        X_tr = X_train[train_index]
        y_tr = y_train[train_index]
        X_te = X_train[test_index]

        clf.fit(X_tr, y_tr)

        oof_train[test_index] = clf.predict_proba(X_te)[:,1]
        test = clf.predict_proba(X_test)[:,1]
        test = test.flatten() 
        oof_test_skf[i, :] = test

    oof_test[:] = oof_test_skf.mean(axis=0)
    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)


# Fit Model
rf_oof_train, rf_oof_test = get_oof(rf_clf, X_train, y_train, X_test)
et_oof_train, et_oof_test = get_oof(et_clf, X_train, y_train, X_test)
ada_oof_train, ada_oof_test = get_oof(ada_clf, X_train, y_train, X_test)
gb_oof_train, gb_oof_test = get_oof(gb_clf, X_train, y_train, X_test)
lg_oof_train, lg_oof_test = get_oof(lg_clf, X_train, y_train, X_test)


# Concatenate Data
X_train_conc = np.concatenate((rf_oof_train, et_oof_train, ada_oof_train, gb_oof_train, lg_oof_train), axis=1)
X_test_conc = np.concatenate((rf_oof_test, et_oof_test, ada_oof_test, gb_oof_test, lg_oof_test), axis=1)


# Save Numpy array np.save(outfile, x)
pickle.dump(X_train_conc, open('X_train_conc.p', 'wb'))
pickle.dump(X_test_conc, open('X_test_conc.p', 'wb'))

# X_train_conc = np.array(pickle.load(open('X_train_conc.p', 'rb')))
# X_test_conc = np.array(pickle.load(open('X_test_conc.p', 'rb')))
