import numpy as np
import pandas as pd
import xgboost

from sklearn.model_selection import GridSearchCV

from xgboost import XGBClassifier
from sklearn.decomposition import PCA

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import Imputer


def xgbmodel(**param):
    xgb = XGBClassifier(**param)
    return xgb


def gridsearch(model, X_train, y_train, **param):
    gsearch = GridSearchCV(estimator=model, param_grid=param, scoring='roc_auc', n_jobs=-1, iid=False, cv=5)
    gsearch.fit(X_train, y_train)
    return gsearch.best_params_, gsearch.best_score_, gsearch.best_estimator_


# Search and Fit
param = {'learning_rate' : 0.1,
         'n_estimators': 177,
         'max_depth': 5,
         'min_child_weight': 1,
         'scale_pos_weight': 1,
         'gamma': 0,
         'subsample': 0.8,
         'colsample_bytree': 0.8,
         'reg_lambda': 1,
         'nthread': 1,
         'seed': 9527}

param_test1 = {
    'max_depth': [3,5,9,12],
    'min_child_weight': [1,3],
    'scale_pos_weight': [1,4,6]
}
param_test2 = { 
    'gamma': [0.3, 0.6] 
}
param_test3 = {
    'reg_lambda': [1, 1.5, 3, 5]
}
param_test4 = {
    'n_estimators': [222,888],
    'learning_rate': [0.01, 0.03, 0.1, 0.3]
}

param_ll = [param_test1, param_test2, param_test3, param_test4]
for i in range(0,4):
    grid_param = param_ll[i]
    clf = xgbmodel(**param)
    gsearch = gridsearch(clf, X_train, y_train, **grid_param)
    print(gsearch.best_estimator_, gsearch.best_params_, gsearch.best_score_)
    param.update(gsearch.best_params_)


print(gsearch.best_estimator_)
pickle.dump(gsearch.best_estimator_, open('best_auto_estimator.p', 'wb'))